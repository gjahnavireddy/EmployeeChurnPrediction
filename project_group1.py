# -*- coding: utf-8 -*-
"""Project_Group1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OeuMVSMQy-qXkj0eUF0EXov9noyHxRAd
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

from google.colab import files
file = files.upload()
df = pd.read_csv("HR-Employee-Attrition.csv")
df.head()

df.head(5)

df.tail(10)

df_shape = df.shape
num_rows, num_columns = df_shape

print(f"Number of rows: {num_rows}")
print(f"Number of columns: {num_columns}")

df.info()

df.describe()

categorical_columns = ['Attrition', 'BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'Over18', 'OverTime']
unique_values_per_column = df[categorical_columns].nunique()
print(unique_values_per_column)

df.head(5)

sns.heatmap(df.isnull(), yticklabels = False, cbar = False, cmap="Blues") #No missing data

df.hist(bins = 30, figsize = (20,20), color = 'teal')

"""Dropping 'EmployeeCount','Standardhours', 'Over18' and 'EmployeeNumber' since they do not change from one employee to the other"""

df.drop(['EmployeeCount', 'StandardHours', 'Over18', 'EmployeeNumber'], axis=1, inplace=True)

correlations = df.corr()
f, ax = plt.subplots(figsize = (20, 20))
sns.heatmap(correlations, annot = True)

"""The level of one's job exhibits a robust correlation with the overall number of working hours expended, indicating a clear association between job hierarchy and the extent of time devoted to work-related activities. Similarly, there exists a strong correlation between the monthly income an individual earns and their job level, underscoring the significance of hierarchical position in influencing income. Moreover, the amount of monthly income demonstrates a pronounced correlation with the total working hours invested, emphasizing the impact of time commitment on financial remuneration. Furthermore, age exhibits a substantial correlation with monthly income, indicating a discernible link between an individual's age and their earning capacity."""

df['Attrition'] = df['Attrition'].apply(lambda x: 1 if x == 'Yes' else 0)
df['OverTime'] = df['OverTime'].apply(lambda x: 1 if x == 'Yes' else 0)

# Set the aesthetic style of the plots
sns.set_style("whitegrid")

# Create a histogram with KDE for 'DistanceFromHome' with the 'Attrition_numeric' column
plt.figure(figsize=(10, 6))
sns.histplot(data=df, x="DistanceFromHome", hue="Attrition", kde=True, multiple="stack", palette="coolwarm")
plt.title("Histogram of Distance From Home by Attrition (Numeric)")
plt.xlabel("Distance From Home")
plt.ylabel("Count")
plt.legend(title="Attrition (Numeric)", labels=['No Attrition', 'Attrition'])
plt.tight_layout()

plt.show()

"""
In terms of distance distribution, the majority of employees tend to reside within a 5-mile radius of their workplace, indicating a common preference for proximity. Surprisingly, there is a higher attrition rate among those in closer proximity, challenging the assumption that longer commutes lead to more attrition. As distance increases beyond 10 miles, attrition rates decline.

Noteworthy anomalies at the 2-mile and 10-mile marks warrant further investigation. While non-attrition employees are consistently present across distances, there is a slight decrease in numbers with increasing distance. The right-skewed Kernel Density Estimation curve implies a concentrated employee presence near the workplace, urging employers to explore factors beyond commuting distance influencing attrition, especially for those living nearby."""

employee_left_df = df[df['Attrition'] == 1]
employee_stayed_df= df[df['Attrition'] == 0]

def plot_kde_YearsWithCurrManager(left, stayed):
    plt.figure(figsize=(12, 7))
    sns.kdeplot(left, label='Employees who left', shade=True, color='orange')
    sns.kdeplot(stayed, label='Employees who Stayed', shade=True, color='teal')
    plt.xlabel('Years With Current Manager')
    plt.legend()
    plt.show()

plot_kde_YearsWithCurrManager(employee_left_df['YearsWithCurrManager'], employee_stayed_df['YearsWithCurrManager'])

"""
The data reveals distinct peaks in employee tenure dynamics. Departures show a significant peak at 2-3 years, indicating a critical attrition period with current managers. Conversely, employees who stay peak around 4-5 years, with a secondary peak at 7 years, suggesting prolonged longevity. The thicker tail in the distribution of employees who stayed signifies substantial persistence. Potential turnover points are identified at 2-3 years and possibly 10-11 years. Implementing retention strategies around the 2-3 year mark with the current manager could mitigate attrition. Managers can use the data to assess practices and consider interventions to enhance satisfaction and retention during crucial tenure periods."""

def plot_kde_distancefromhome(left, stayed):
    plt.figure(figsize=(12, 7))
    sns.kdeplot(left, label='Employees who left', shade=True, color='orange')
    sns.kdeplot(stayed, label='Employees who Stayed', shade=True, color='teal')
    plt.xlabel('Distance From Home')
    plt.legend()
    plt.show()


plot_kde_distancefromhome(employee_left_df['DistanceFromHome'], employee_stayed_df['DistanceFromHome'])

"""The primary commuting distance for both departing and remaining employees peaks at around 10 miles, indicating it may not be the sole factor influencing their decisions. Departing employees show a concentration in shorter distances and a notable attrition peak for those living very close to work. A secondary peak at 20-30 miles suggests longer commutes may contribute to departure, while those who stay have a flatter distribution, suggesting retention across distances up to 25 miles. Human Resources should investigate additional factors influencing turnover, particularly for employees in close proximity, as commuting distance is just one aspect."""

def plot_attrition_across_categories(df):
    custom_palette = ["Teal", "#FFD580"]

    fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(20, 20))

    sns.countplot(x='MaritalStatus', hue='Attrition', data=df, ax=axes[0], palette=custom_palette)
    axes[0].set_title('Marital Status vs Attrition')

    sns.countplot(x='JobLevel', hue='Attrition', data=df, ax=axes[1], palette=custom_palette)
    axes[1].set_title('Job Level vs Attrition')

    plt.tight_layout()
    plt.show()

plot_attrition_across_categories(df)

"""Sales Executives, Laboratory Technicians, Sales Representatives, and Research Scientists exhibit significantly higher attrition rates than other job roles, contrasting with the lower attrition rates observed in Managers, Research Directors, and Human Resources staff. The bar chart strongly suggests that roles with higher stress or perceived job insecurity tend to experience elevated turnover.

In the exploration of Marital Status versus Attrition:
Single employees show a notably higher attrition rate than married and divorced counterparts, with the latter group showcasing the lowest attrition rate. This pattern implies that factors like marital responsibilities or stability associated with marriage and divorce influence an individual's likelihood of staying employed.

Regarding Job Level and Attrition:
Employees at job level 1 have the highest attrition rate, followed by level 2. Attrition decreases significantly with higher job levels, with levels 4 and 5 having the lowest rates. Higher job levels, likely indicating more senior positions, correlate with enhanced job retention, possibly due to increased satisfaction, superior salaries, or greater commitment.

Across all charts, attrition is visually represented by two colors, 'Attrition = 0' for employees who stayed and 'Attrition = 1' for those who left. This visual representation offers a comprehensive overview of attrition distribution across job roles, marital statuses, and job levels. The insights derived from this data could prove beneficial for HR in designing retention strategies and understanding factors contributing to turnover.

"""

plt.figure(figsize=(15, 10))
plt.boxplot([df[df['Gender'] == 'Female']['MonthlyIncome'],
             df[df['Gender'] == 'Male']['MonthlyIncome']],
            vert=False)

plt.yticks([1, 2], ['Female', 'Male'])


plt.xlabel('Monthly Income')
plt.ylabel('Gender')


plt.title('Monthly Income by Gender')

plt.show()

jobrole_palette = {
    'Sales Executive': 'lightskyblue',
    'Research Scientist': 'Teal',
    'Laboratory Technician': 'lightcoral',
    'Manufacturing Director': 'Blue',
    'Healthcare Representative': 'yellow',
    'Manager': 'Orange',
    'Sales Representative': 'Pink',
    'Research Director': 'brown',
    'Human Resources': 'lightgoldenrodyellow'
}
plt.figure(figsize=(15, 10))
sns.boxplot(x = 'MonthlyIncome', y = 'JobRole', data = df,palette=jobrole_palette)

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score
X = df.drop('Attrition', axis=1)
y = df['Attrition']
X = pd.get_dummies(X, drop_first=True)

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the logistic regression model
log_reg = LogisticRegression(max_iter=1000)
log_reg.fit(X_train, y_train)

# Evaluate the model
predictions = log_reg.predict(X_test)
print('Accuracy:', accuracy_score(y_test, predictions))
print('Classification Report:', classification_report(y_test, predictions))

from sklearn.ensemble import RandomForestClassifier


# Prepare data for modeling
X = df.drop('Attrition', axis=1)
y = df['Attrition']
X = pd.get_dummies(X, drop_first=True)

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the Random Forest classifier
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)  # You can adjust parameters
rf_classifier.fit(X_train, y_train)

# Evaluate the model
predictions = rf_classifier.predict(X_test)
print('Accuracy:', accuracy_score(y_test, predictions))
print('Classification Report:', classification_report(y_test, predictions))

from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

X = pd.get_dummies(df.drop('Attrition', axis=1), drop_first=True)
y = df['Attrition'].values

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define the model
model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.5),
    Dense(32, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=2)

# Evaluate the model on test data
y_pred = model.predict(X_test) > 0.5
print('Accuracy:', accuracy_score(y_test, y_pred))
print('Classification Report:', classification_report(y_test, y_pred))





import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from keras.models import Sequential
from keras.layers import Dense, Dropout
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_curve, auc, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import seaborn as sns
import random
# Assuming df is your original dataframe

# Convert categorical variables to dummy variables
X = pd.get_dummies(df.drop('Attrition', axis=1), drop_first=True)
y = df['Attrition'].values

# Split the data into training and testing sets (for logistic regression and random forest)
X_train_LR_RF, X_test_LR_RF, y_train_LR_RF, y_test_LR_RF = train_test_split(X, y, test_size=0.2, random_state=42)

# Further split the training data for deep learning model to separate out a validation set
X_train_DL, X_val_DL, y_train_DL, y_val_DL = train_test_split(X_train_LR_RF, y_train_LR_RF, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2

# Feature scaling for deep learning model
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_DL)
X_val_scaled = scaler.transform(X_val_DL)
X_test_scaled = scaler.transform(X_test_LR_RF)

# Set random seed for reproducibility
np.random.seed(42)
random.seed(42)
tf.random.set_seed(42)

# Continue with your model definition and training as before
model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),
    Dropout(0.5),  # Consider adjusting dropout if necessary
    Dense(32, activation='relu'),
    Dropout(0.5),  # Consider adjusting dropout if necessary
    Dense(1, activation='sigmoid')
])
# Rest of the code remains the same

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.fit(X_train_scaled, y_train_DL, epochs=50, batch_size=32, validation_data=(X_val_scaled, y_val_DL), verbose=0)

# Logistic Regression and Random Forest models
log_reg = LogisticRegression(max_iter=1000)
log_reg.fit(X_train_LR_RF, y_train_LR_RF)

rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
rf_classifier.fit(X_train_LR_RF, y_train_LR_RF)

# Predictions and evaluation
y_pred_log_reg = log_reg.predict(X_test_LR_RF)
y_pred_proba_log_reg = log_reg.predict_proba(X_test_LR_RF)[:, 1]

y_pred_rf = rf_classifier.predict(X_test_LR_RF)
y_pred_proba_rf = rf_classifier.predict_proba(X_test_LR_RF)[:, 1]

y_pred_dl = (model.predict(X_test_scaled) > 0.5).astype(int).flatten()  # For binary classification
y_pred_proba_dl = model.predict(X_test_scaled).flatten()  # This is the probability for ROC curve


# Function to plot ROC curve and confusion matrix
def plot_single_roc_curve(y_test, y_pred_proba, model_name):
    plt.figure(figsize=(8, 6))
    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], 'k--')  # Plot the random chance line
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(f'ROC Curve for {model_name}')
    plt.legend(loc="lower right")
    plt.show()
# Use the existing functions as defined earlier
# Plot ROC curve for Logistic Regression
plot_single_roc_curve(y_test_LR_RF, y_pred_proba_log_reg, 'Logistic Regression')

# Plot ROC curve for Random Forest
plot_single_roc_curve(y_test_LR_RF, y_pred_proba_rf, 'Random Forest')

# Plot ROC curve for Deep Learning model
plot_single_roc_curve(y_test_LR_RF, y_pred_proba_dl, 'Deep Learning')
# Function to plot combined ROC curves for all models
def plot_combined_roc_curves(y_test, model_predictions, model_names):
    plt.figure(figsize=(10, 8))
    for y_pred_proba, model_name in zip(model_predictions, model_names):
        fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)
        plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')

    # Plot the random chance line
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Combined ROC Curves')
    plt.legend(loc="lower right")
    plt.show()

  # Function to plot confusion matrix for multiple models
def plot_confusion_matrix(y_test, y_preds, model_names):
    for i, y_pred in enumerate(y_preds):
        cm = confusion_matrix(y_test, y_pred)
        plt.figure(figsize=(5, 4))
        sns.heatmap(cm, annot=True, fmt="d")
        plt.title(f'Confusion Matrix for {model_names[i]}')
        plt.ylabel('Actual label')
        plt.xlabel('Predicted label')
        plt.show()

# Summary table of metrics
def generate_summary_table(y_test, y_preds, model_names):
    metrics_summary = {
        'Model': [],
        'Accuracy': [],
        'Precision': [],
        'Recall': [],
        'F1 Score': []
    }
    from sklearn.metrics import precision_score, recall_score, f1_score
    for i, y_pred in enumerate(y_preds):
        metrics_summary['Model'].append(model_names[i])
        metrics_summary['Accuracy'].append(accuracy_score(y_test, y_pred))
        metrics_summary['Precision'].append(precision_score(y_test, y_pred))
        metrics_summary['Recall'].append(recall_score(y_test, y_pred))
        metrics_summary['F1 Score'].append(f1_score(y_test, y_pred))
    df_metrics_summary = pd.DataFrame(metrics_summary)
    return df_metrics_summary

# Prepare your model names and predicted probabilities for the positive class
model_names = ['Logistic Regression', 'Random Forest', 'Deep Learning']
model_predictions = [y_pred_proba_log_reg, y_pred_proba_rf, y_pred_proba_dl]

# Plot the combined ROC curves
plot_combined_roc_curves(y_test_LR_RF, model_predictions, model_names)
# Plotting and summary table
model_names = ['Logistic Regression', 'Random Forest', 'Deep Learning']
plot_confusion_matrix(y_test_LR_RF, [y_pred_log_reg, y_pred_rf, y_pred_dl], model_names)
summary_table = generate_summary_table(y_test_LR_RF, [y_pred_log_reg, y_pred_rf, y_pred_dl], model_names)
summary_table